<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Shaoan Wang</title>

    <meta name="author" content="Shaoan Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Shaoan Wang
                </p>
                <p>I'm a fourth-year PhD student at College of Engineering at Peking University, where I have been advised by Prof. <a href="https://www.coe.pku.edu.cn/teaching/manufacturing/9993.html">Junzhi Yu</a>. Currently, I'm also a research intern at an embodied AI startup <a href="https://www.galbot.com/">GALBOT</a>, supervised by Prof. <a href="https://hughw19.github.io">He Wang</a> and Dr. <a href="https://scholar.google.com/citations?user=X7M0I8kAAAAJ&hl=en">Zhizheng Zhang</a>. Before that, I completed my Bachelor's in Robotics at Beijing Institute of Technology in 2021, supervised by Prof. <a href="https://smen.bit.edu.cn/szdw/szml/znjqryjs/qb08/4ada85fc3d4e4ebd8d84480267e36754.htm#">Huaping Wang</a>.
                </p>
                <p>Nowadays, I'm interested in embodied AI, with a specific focus on visual-language navigation and multimodal robot perception. In my previous work, I concentrated on achieving high‑precision pose estimation for curved surfaces by leveraging visual fiducial markers.
                </p>
                <p style="text-align:center">
                  <a href="mailto:wangshaoan@stu.pku.edu.cn">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=m3FCQrkAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/wsakobe/">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/wsa.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/wsa.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications (Selected)</h2>
                
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr onmouseout="uni_navid_stop()" onmouseover="uni_navid_start()" >
              <td style="padding:20px;width:30%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='uni_navid_image'>
                  <img src="images/uni-navid/uni_navid.gif" width="220" height="165">
                  </div>
                  <img src='images/uni-navid/uni_navid.png' width="220" height="165">
                </div>
                <script type="text/javascript">
                  function uni_navid_start() {
                    document.getElementById('uni_navid_image').style.opacity = "1";
                  }
                  function uni_navid_stop() {
                    document.getElementById('uni_navid_image').style.opacity = "0";
                  }
                  uni_navid_stop()
                </script>
              </td>
              <td style="padding:20px;width:70%;vertical-align:middle">
                <a href="https://pku-epic.github.io/Uni-NaVid/">
                <span class="papertitle">Uni-NaVid: A Video-based Vision-Language-Action Model for Unifying Embodied Navigation Tasks</span>
                </a>
                <br>
                Jiazhao Zhang, Kunyu Wang, <strong>Shaoan Wang</strong>, Minghan Li, Haoran Liu, Songlin Wei, Zhongyuan Wang, Zhizheng Zhang<sup>†</sup>, He Wang<sup>†</sup> 
                <br>
                <em><b>RSS 2025</b></em>
                <br>
                <a href="https://arxiv.org/pdf/2412.06224">[PDF]</a>
                <a href="https://pku-epic.github.io/Uni-NaVid/">[Project page]</a>
                <p></p>
                <p>
                  We present Uni-NaVid, the first video-based vision-language-action (VLA) model designed to unify diverse embodied navigation tasks and enable seamless navigation for mixed long-horizon tasks in unseen real-world environments.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/ef-calib.png' width="220">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">EF-Calib: Spatiotemporal Calibration of Event- and Frame-based Cameras Using Continuous-Time Trajectories</span>
                <br>
                <strong>Shaoan Wang</strong>, Zhanhua Xin, Yaoqing Hu, Dongyue Li, Mingzhu Zhu, Junzhi Yu<sup>†</sup></a>
                <br>
                <em><b>IEEE Robotics and Automation Letters</b></em>, 2024
                <br>
                <a href="data/2024ral.pdf">[PDF]</a>
                <a href="data/ral2024.bib">[BibTeX]</a>
                <a href="https://github.com/wsakobe/EF-Calib">[Code]</a>
                <p></p>
                <p>A novel spatiotemporal calibration toolkit for event‑based and frame-based camera system.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/suturerobot.png' width="220">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Spatially Compact Visual Navigation System for Automated Suturing Robot Toward Oral and Maxillofacial Surgery</span>
                <br>
                <strong>Shaoan Wang</strong>, Qiming Zhao, Dongyue Li, Yaoqing Hu, Mingzhu Zhu, Fusong Yuan, Jinyan Shao, Junzhi Yu<sup>†</sup></a>
                <br>
                <em><b>IEEE Transactions on Instrumentation and Measurement</b></em>, 2024
                <br>
                <a href="data/2024tim.pdf">[PDF]</a>
                <a href="data/tim2024.bib">[BibTeX]</a>
                
                <p></p>
                <p>A spatially compact visual navigation system for autonomous OMS (Oral and Maxillofacial Surgery) suture robot.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/cylindertag.png' width="220">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
             
                  <span class="papertitle">CylinderTag: An Accurate and Flexible Marker for Cylinder-Shape Objects Pose Estimation Based on Projective Invariants</span>
                
                <br>
                <strong>Shaoan Wang</strong>, Mingzhu Zhu, Yaoqing Hu, Dongyue Li, Fusong Yuan, Junzhi Yu<sup>†</sup></a>
                <br>
                <em><b>IEEE Transactions on Visualization and Computer Graphics</b></em>, 2024
                <br>
                <a href="data/2024tvcg.pdf">[PDF]</a>
                <a href="data/tvcg2024.bib">[BibTeX]</a>
                <a href="https://github.com/wsakobe/CylinderTag">[Code]</a>
                <p></p>
                <p>A visual marker based on projective invariance called CylinderTag is developed, which provides a new solution for high‑precision position estimation of curved objects.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/tim22.png' width="220">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                
                  <span class="papertitle">Accurate Detection and Localization of Curved Checkerboard-Like Marker Based on Quadratic Form</span>
                
                <br>
                <strong>Shaoan Wang</strong>, Mingzhu Zhu, Yaoqing Hu, Dongyue Li, Fusong Yuan, Junzhi Yu*</a>
                <br>
                <em><b>IEEE Transactions on Instrumentation and Measurement</b></em>, 2022
                <br>
                <a href="data/2022tim.pdf">[PDF]</a>
                <a href="data/tim2022.bib">[BibTeX]</a>
                <a href="https://github.com/wsakobe/Marker_curved-surface">[Code]</a>
                <p></p>
                <p>A subpixel corner detector for curved checkerboard-like markers based on quadratic form.</p>
              </td>
            </tr>

          </tbody></table>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  The website template was adapted from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>